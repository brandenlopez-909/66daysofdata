{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPAM OR HAM\n",
    "\n",
    "In this exercise we are tasked with building classification model for SPAM/HAM emails.\n",
    "\n",
    "First let's see the ReadMe:."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the SpamAssassin public mail corpus.  This is a selection of mail\n",
    "messages, suitable for use in testing spam filtering systems.  Pertinent\n",
    "points:\n",
    "\n",
    "  - All headers are reproduced in full.  Some address obfuscation has taken\n",
    "    place, and hostnames in some cases have been replaced with\n",
    "    \"spamassassin.taint.org\" (which has a valid MX record).  In most cases\n",
    "    though, the headers appear as they were received.\n",
    "\n",
    "  - All of these messages were posted to public fora, were sent to me in the\n",
    "    knowledge that they may be made public, were sent by me, or originated as\n",
    "    newsletters from public news web sites.\n",
    "\n",
    "  - relying on data from public networked blacklists like DNSBLs, Razor, DCC\n",
    "    or Pyzor for identification of these messages is not recommended, as a\n",
    "    previous downloader of this corpus might have reported them!\n",
    "\n",
    "  - Copyright for the text in the messages remains with the original senders.\n",
    "\n",
    "\n",
    "OK, now onto the corpus description.  It's split into three parts, as follows:\n",
    "\n",
    "  - spam: 500 spam messages, all received from non-spam-trap sources.\n",
    "\n",
    "  - easy_ham: 2500 non-spam messages.  These are typically quite easy to\n",
    "    differentiate from spam, since they frequently do not contain any spammish\n",
    "    signatures (like HTML etc).\n",
    "\n",
    "  - hard_ham: 250 non-spam messages which are closer in many respects to\n",
    "    typical spam: use of HTML, unusual HTML markup, coloured text,\n",
    "    \"spammish-sounding\" phrases etc.\n",
    "\n",
    "  - easy_ham_2: 1400 non-spam messages.  A more recent addition to the set.\n",
    "\n",
    "  - spam_2: 1397 spam messages.  Again, more recent.\n",
    "\n",
    "Total count: 6047 messages, with about a 31% spam ratio.\n",
    "\n",
    "The corpora are prefixed with the date they were assembled.  They are\n",
    "compressed using \"bzip2\".  The messages are named by a message number and\n",
    "their MD5 checksum.\n",
    "\n",
    "\n",
    "When I first grabbed the data I was very unconfident beacause the file names are were a message number and the types were the MD5 checksum, neither of these I had encountered before. So I went ahead and took the source code from [HOML's repository](https://github.com/ageron/handson-ml2/blob/master/03_classification.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import urllib\n",
    "#Where we download the data from\n",
    "DOWNLOAD_ROOT = \"http://spamassassin.apache.org/old/publiccorpus/\"\n",
    "HAM_URL = DOWNLOAD_ROOT + \"20030228_easy_ham.tar.bz2\"\n",
    "SPAM_URL = DOWNLOAD_ROOT + \"20030228_spam.tar.bz2\"\n",
    "SPAM_PATH = os.path.join(\"datasets\", \"spam\")\n",
    "\n",
    "#Now when you call fetch_housing_data(), it creates a datasets/housing directory in your workspace,\n",
    "#downloads the housing.tgz file, and extracts the housing.csv file from it in this directory.\n",
    "    \n",
    "\n",
    "def fetch_spam_data(ham_url=HAM_URL, spam_url=SPAM_URL, spam_path=SPAM_PATH):\n",
    "    if not os.path.isdir(spam_path):\n",
    "        os.makedirs(spam_path)\n",
    "    for filename, url in ((\"ham.tar.bz2\", ham_url), (\"spam.tar.bz2\", spam_url)):\n",
    "        path = os.path.join(spam_path, filename)\n",
    "        if not os.path.isfile(path):\n",
    "            urllib.request.urlretrieve(url, path)\n",
    "        tar_bz2_file = tarfile.open(path)\n",
    "        tar_bz2_file.extractall(path=spam_path)\n",
    "        tar_bz2_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_spam_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HAM_DIR = os.path.join(SPAM_PATH, \"easy_ham\")\n",
    "SPAM_DIR = os.path.join(SPAM_PATH, \"spam\")\n",
    "#We get the files containg emails\n",
    "ham_filenames = [name for name in sorted(os.listdir(HAM_DIR)) if len(name) > 20]\n",
    "spam_filenames = [name for name in sorted(os.listdir(SPAM_DIR)) if len(name) > 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cmds']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[name for name in sorted(os.listdir(HAM_DIR)) if len(name) <20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the textbook's solutions we grab anyname that is more than 20 characters long. This is because there is a file named cmds, which appear to harbor checksums of every file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500 500\n"
     ]
    }
   ],
   "source": [
    "print(len(ham_filenames),len(spam_filenames) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without the handbook I would have never learned about Python's [email module](https://docs.python.org/3/library/email.html). This module is used to process emails that have been saved according to RFC standards. Wow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import email\n",
    "import email.policy\n",
    "\n",
    "def load_email(is_spam, filename, spam_path=SPAM_PATH):\n",
    "    directory = \"spam\" if is_spam else \"easy_ham\"\n",
    "    with open(os.path.join(spam_path, directory, filename), \"rb\") as f:\n",
    "        return email.parser.BytesParser(policy=email.policy.default).parse(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_emails = [load_email(is_spam=False, filename=name) for name in ham_filenames]\n",
    "spam_emails = [load_email(is_spam=True, filename=name) for name in spam_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Martin A posted:\n",
      "Tassos Papadopoulos, the Greek sculptor behind the plan, judged that the\n",
      " limestone of Mount Kerdylio, 70 miles east of Salonika and not far from the\n",
      " Mount Athos monastic community, was ideal for the patriotic sculpture. \n",
      " \n",
      " As well as Alexander's granite features, 240 ft high and 170 ft wide, a\n",
      " museum, a restored amphitheatre and car park for admiring crowds are\n",
      "planned\n",
      "---------------------\n",
      "So is this mountain limestone or granite?\n",
      "If it's limestone, it'll weather pretty fast.\n",
      "\n",
      "------------------------ Yahoo! Groups Sponsor ---------------------~-->\n",
      "4 DVDs Free +s&p Join Now\n",
      "http://us.click.yahoo.com/pt6YBB/NXiEAA/mG3HAA/7gSolB/TM\n",
      "---------------------------------------------------------------------~->\n",
      "\n",
      "To unsubscribe from this group, send an email to:\n",
      "forteana-unsubscribe@egroups.com\n",
      "\n",
      " \n",
      "\n",
      "Your use of Yahoo! Groups is subject to http://docs.yahoo.com/info/terms/ \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ham_emails[1].get_content())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From my understanding of the above code, emails are saved in a particular format as bytes when transporting them. The email library allows us to access those emails using the get_content() method.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "email.message.EmailMessage"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ham_emails[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class EmailMessage in module email.message:\n",
      "\n",
      "class EmailMessage(MIMEPart)\n",
      " |  EmailMessage(policy=None)\n",
      " |  \n",
      " |  Basic message object.\n",
      " |  \n",
      " |  A message object is defined as something that has a bunch of RFC 2822\n",
      " |  headers and a payload.  It may optionally have an envelope header\n",
      " |  (a.k.a. Unix-From or From_ header).  If the message is a container (i.e. a\n",
      " |  multipart or a message/rfc822), then the payload is a list of Message\n",
      " |  objects, otherwise it is a string.\n",
      " |  \n",
      " |  Message objects implement part of the `mapping' interface, which assumes\n",
      " |  there is exactly one occurrence of the header per message.  Some headers\n",
      " |  do in fact appear multiple times (e.g. Received) and for those headers,\n",
      " |  you must use the explicit API to set or get all the headers.  Not all of\n",
      " |  the mapping methods are implemented.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      EmailMessage\n",
      " |      MIMEPart\n",
      " |      Message\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  set_content(self, *args, **kw)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from MIMEPart:\n",
      " |  \n",
      " |  __init__(self, policy=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return the entire formatted message as a string.\n",
      " |  \n",
      " |  add_alternative(self, *args, **kw)\n",
      " |  \n",
      " |  add_attachment(self, *args, **kw)\n",
      " |  \n",
      " |  add_related(self, *args, **kw)\n",
      " |  \n",
      " |  as_string(self, unixfrom=False, maxheaderlen=None, policy=None)\n",
      " |      Return the entire formatted message as a string.\n",
      " |      \n",
      " |      Optional 'unixfrom', when true, means include the Unix From_ envelope\n",
      " |      header.  maxheaderlen is retained for backward compatibility with the\n",
      " |      base Message class, but defaults to None, meaning that the policy value\n",
      " |      for max_line_length controls the header maximum length.  'policy' is\n",
      " |      passed to the Generator instance used to serialize the mesasge; if it\n",
      " |      is not specified the policy associated with the message instance is\n",
      " |      used.\n",
      " |  \n",
      " |  clear(self)\n",
      " |  \n",
      " |  clear_content(self)\n",
      " |  \n",
      " |  get_body(self, preferencelist=('related', 'html', 'plain'))\n",
      " |      Return best candidate mime part for display as 'body' of message.\n",
      " |      \n",
      " |      Do a depth first search, starting with self, looking for the first part\n",
      " |      matching each of the items in preferencelist, and return the part\n",
      " |      corresponding to the first item that has a match, or None if no items\n",
      " |      have a match.  If 'related' is not included in preferencelist, consider\n",
      " |      the root part of any multipart/related encountered as a candidate\n",
      " |      match.  Ignore parts with 'Content-Disposition: attachment'.\n",
      " |  \n",
      " |  get_content(self, *args, content_manager=None, **kw)\n",
      " |  \n",
      " |  is_attachment(self)\n",
      " |  \n",
      " |  iter_attachments(self)\n",
      " |      Return an iterator over the non-main parts of a multipart.\n",
      " |      \n",
      " |      Skip the first of each occurrence of text/plain, text/html,\n",
      " |      multipart/related, or multipart/alternative in the multipart (unless\n",
      " |      they have a 'Content-Disposition: attachment' header) and include all\n",
      " |      remaining subparts in the returned iterator.  When applied to a\n",
      " |      multipart/related, return all parts except the root part.  Return an\n",
      " |      empty iterator when applied to a multipart/alternative or a\n",
      " |      non-multipart.\n",
      " |  \n",
      " |  iter_parts(self)\n",
      " |      Return an iterator over all immediate subparts of a multipart.\n",
      " |      \n",
      " |      Return an empty iterator for a non-multipart.\n",
      " |  \n",
      " |  make_alternative(self, boundary=None)\n",
      " |  \n",
      " |  make_mixed(self, boundary=None)\n",
      " |  \n",
      " |  make_related(self, boundary=None)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from Message:\n",
      " |  \n",
      " |  __bytes__(self)\n",
      " |      Return the entire formatted message as a bytes object.\n",
      " |  \n",
      " |  __contains__(self, name)\n",
      " |  \n",
      " |  __delitem__(self, name)\n",
      " |      Delete all occurrences of a header, if present.\n",
      " |      \n",
      " |      Does not raise an exception if the header is missing.\n",
      " |  \n",
      " |  __getitem__(self, name)\n",
      " |      Get a header value.\n",
      " |      \n",
      " |      Return None if the header is missing instead of raising an exception.\n",
      " |      \n",
      " |      Note that if the header appeared multiple times, exactly which\n",
      " |      occurrence gets returned is undefined.  Use get_all() to get all\n",
      " |      the values matching a header field name.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Return the total number of headers, including duplicates.\n",
      " |  \n",
      " |  __setitem__(self, name, val)\n",
      " |      Set the value of a header.\n",
      " |      \n",
      " |      Note: this does not overwrite an existing header with the same field\n",
      " |      name.  Use __delitem__() first to delete any existing headers.\n",
      " |  \n",
      " |  add_header(self, _name, _value, **_params)\n",
      " |      Extended header setting.\n",
      " |      \n",
      " |      name is the header field to add.  keyword arguments can be used to set\n",
      " |      additional parameters for the header field, with underscores converted\n",
      " |      to dashes.  Normally the parameter will be added as key=\"value\" unless\n",
      " |      value is None, in which case only the key will be added.  If a\n",
      " |      parameter value contains non-ASCII characters it can be specified as a\n",
      " |      three-tuple of (charset, language, value), in which case it will be\n",
      " |      encoded according to RFC2231 rules.  Otherwise it will be encoded using\n",
      " |      the utf-8 charset and a language of ''.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      msg.add_header('content-disposition', 'attachment', filename='bud.gif')\n",
      " |      msg.add_header('content-disposition', 'attachment',\n",
      " |                     filename=('utf-8', '', Fußballer.ppt'))\n",
      " |      msg.add_header('content-disposition', 'attachment',\n",
      " |                     filename='Fußballer.ppt'))\n",
      " |  \n",
      " |  as_bytes(self, unixfrom=False, policy=None)\n",
      " |      Return the entire formatted message as a bytes object.\n",
      " |      \n",
      " |      Optional 'unixfrom', when true, means include the Unix From_ envelope\n",
      " |      header.  'policy' is passed to the BytesGenerator instance used to\n",
      " |      serialize the message; if not specified the policy associated with\n",
      " |      the message instance is used.\n",
      " |  \n",
      " |  attach(self, payload)\n",
      " |      Add the given payload to the current payload.\n",
      " |      \n",
      " |      The current payload will always be a list of objects after this method\n",
      " |      is called.  If you want to set the payload to a scalar object, use\n",
      " |      set_payload() instead.\n",
      " |  \n",
      " |  del_param(self, param, header='content-type', requote=True)\n",
      " |      Remove the given parameter completely from the Content-Type header.\n",
      " |      \n",
      " |      The header will be re-written in place without the parameter or its\n",
      " |      value. All values will be quoted as necessary unless requote is\n",
      " |      False.  Optional header specifies an alternative to the Content-Type\n",
      " |      header.\n",
      " |  \n",
      " |  get(self, name, failobj=None)\n",
      " |      Get a header value.\n",
      " |      \n",
      " |      Like __getitem__() but return failobj instead of None when the field\n",
      " |      is missing.\n",
      " |  \n",
      " |  get_all(self, name, failobj=None)\n",
      " |      Return a list of all the values for the named field.\n",
      " |      \n",
      " |      These will be sorted in the order they appeared in the original\n",
      " |      message, and may contain duplicates.  Any fields deleted and\n",
      " |      re-inserted are always appended to the header list.\n",
      " |      \n",
      " |      If no such fields exist, failobj is returned (defaults to None).\n",
      " |  \n",
      " |  get_boundary(self, failobj=None)\n",
      " |      Return the boundary associated with the payload if present.\n",
      " |      \n",
      " |      The boundary is extracted from the Content-Type header's `boundary'\n",
      " |      parameter, and it is unquoted.\n",
      " |  \n",
      " |  get_charset(self)\n",
      " |      Return the Charset instance associated with the message's payload.\n",
      " |  \n",
      " |  get_charsets(self, failobj=None)\n",
      " |      Return a list containing the charset(s) used in this message.\n",
      " |      \n",
      " |      The returned list of items describes the Content-Type headers'\n",
      " |      charset parameter for this message and all the subparts in its\n",
      " |      payload.\n",
      " |      \n",
      " |      Each item will either be a string (the value of the charset parameter\n",
      " |      in the Content-Type header of that part) or the value of the\n",
      " |      'failobj' parameter (defaults to None), if the part does not have a\n",
      " |      main MIME type of \"text\", or the charset is not defined.\n",
      " |      \n",
      " |      The list will contain one string for each part of the message, plus\n",
      " |      one for the container message (i.e. self), so that a non-multipart\n",
      " |      message will still return a list of length 1.\n",
      " |  \n",
      " |  get_content_charset(self, failobj=None)\n",
      " |      Return the charset parameter of the Content-Type header.\n",
      " |      \n",
      " |      The returned string is always coerced to lower case.  If there is no\n",
      " |      Content-Type header, or if that header has no charset parameter,\n",
      " |      failobj is returned.\n",
      " |  \n",
      " |  get_content_disposition(self)\n",
      " |      Return the message's content-disposition if it exists, or None.\n",
      " |      \n",
      " |      The return values can be either 'inline', 'attachment' or None\n",
      " |      according to the rfc2183.\n",
      " |  \n",
      " |  get_content_maintype(self)\n",
      " |      Return the message's main content type.\n",
      " |      \n",
      " |      This is the `maintype' part of the string returned by\n",
      " |      get_content_type().\n",
      " |  \n",
      " |  get_content_subtype(self)\n",
      " |      Returns the message's sub-content type.\n",
      " |      \n",
      " |      This is the `subtype' part of the string returned by\n",
      " |      get_content_type().\n",
      " |  \n",
      " |  get_content_type(self)\n",
      " |      Return the message's content type.\n",
      " |      \n",
      " |      The returned string is coerced to lower case of the form\n",
      " |      `maintype/subtype'.  If there was no Content-Type header in the\n",
      " |      message, the default type as given by get_default_type() will be\n",
      " |      returned.  Since according to RFC 2045, messages always have a default\n",
      " |      type this will always return a value.\n",
      " |      \n",
      " |      RFC 2045 defines a message's default type to be text/plain unless it\n",
      " |      appears inside a multipart/digest container, in which case it would be\n",
      " |      message/rfc822.\n",
      " |  \n",
      " |  get_default_type(self)\n",
      " |      Return the `default' content type.\n",
      " |      \n",
      " |      Most messages have a default content type of text/plain, except for\n",
      " |      messages that are subparts of multipart/digest containers.  Such\n",
      " |      subparts have a default content type of message/rfc822.\n",
      " |  \n",
      " |  get_filename(self, failobj=None)\n",
      " |      Return the filename associated with the payload if present.\n",
      " |      \n",
      " |      The filename is extracted from the Content-Disposition header's\n",
      " |      `filename' parameter, and it is unquoted.  If that header is missing\n",
      " |      the `filename' parameter, this method falls back to looking for the\n",
      " |      `name' parameter.\n",
      " |  \n",
      " |  get_param(self, param, failobj=None, header='content-type', unquote=True)\n",
      " |      Return the parameter value if found in the Content-Type header.\n",
      " |      \n",
      " |      Optional failobj is the object to return if there is no Content-Type\n",
      " |      header, or the Content-Type header has no such parameter.  Optional\n",
      " |      header is the header to search instead of Content-Type.\n",
      " |      \n",
      " |      Parameter keys are always compared case insensitively.  The return\n",
      " |      value can either be a string, or a 3-tuple if the parameter was RFC\n",
      " |      2231 encoded.  When it's a 3-tuple, the elements of the value are of\n",
      " |      the form (CHARSET, LANGUAGE, VALUE).  Note that both CHARSET and\n",
      " |      LANGUAGE can be None, in which case you should consider VALUE to be\n",
      " |      encoded in the us-ascii charset.  You can usually ignore LANGUAGE.\n",
      " |      The parameter value (either the returned string, or the VALUE item in\n",
      " |      the 3-tuple) is always unquoted, unless unquote is set to False.\n",
      " |      \n",
      " |      If your application doesn't care whether the parameter was RFC 2231\n",
      " |      encoded, it can turn the return value into a string as follows:\n",
      " |      \n",
      " |          rawparam = msg.get_param('foo')\n",
      " |          param = email.utils.collapse_rfc2231_value(rawparam)\n",
      " |  \n",
      " |  get_params(self, failobj=None, header='content-type', unquote=True)\n",
      " |      Return the message's Content-Type parameters, as a list.\n",
      " |      \n",
      " |      The elements of the returned list are 2-tuples of key/value pairs, as\n",
      " |      split on the `=' sign.  The left hand side of the `=' is the key,\n",
      " |      while the right hand side is the value.  If there is no `=' sign in\n",
      " |      the parameter the value is the empty string.  The value is as\n",
      " |      described in the get_param() method.\n",
      " |      \n",
      " |      Optional failobj is the object to return if there is no Content-Type\n",
      " |      header.  Optional header is the header to search instead of\n",
      " |      Content-Type.  If unquote is True, the value is unquoted.\n",
      " |  \n",
      " |  get_payload(self, i=None, decode=False)\n",
      " |      Return a reference to the payload.\n",
      " |      \n",
      " |      The payload will either be a list object or a string.  If you mutate\n",
      " |      the list object, you modify the message's payload in place.  Optional\n",
      " |      i returns that index into the payload.\n",
      " |      \n",
      " |      Optional decode is a flag indicating whether the payload should be\n",
      " |      decoded or not, according to the Content-Transfer-Encoding header\n",
      " |      (default is False).\n",
      " |      \n",
      " |      When True and the message is not a multipart, the payload will be\n",
      " |      decoded if this header's value is `quoted-printable' or `base64'.  If\n",
      " |      some other encoding is used, or the header is missing, or if the\n",
      " |      payload has bogus data (i.e. bogus base64 or uuencoded data), the\n",
      " |      payload is returned as-is.\n",
      " |      \n",
      " |      If the message is a multipart and the decode flag is True, then None\n",
      " |      is returned.\n",
      " |  \n",
      " |  get_unixfrom(self)\n",
      " |  \n",
      " |  is_multipart(self)\n",
      " |      Return True if the message consists of multiple parts.\n",
      " |  \n",
      " |  items(self)\n",
      " |      Get all the message's header fields and values.\n",
      " |      \n",
      " |      These will be sorted in the order they appeared in the original\n",
      " |      message, or were added to the message, and may contain duplicates.\n",
      " |      Any fields deleted and re-inserted are always appended to the header\n",
      " |      list.\n",
      " |  \n",
      " |  keys(self)\n",
      " |      Return a list of all the message's header field names.\n",
      " |      \n",
      " |      These will be sorted in the order they appeared in the original\n",
      " |      message, or were added to the message, and may contain duplicates.\n",
      " |      Any fields deleted and re-inserted are always appended to the header\n",
      " |      list.\n",
      " |  \n",
      " |  raw_items(self)\n",
      " |      Return the (name, value) header pairs without modification.\n",
      " |      \n",
      " |      This is an \"internal\" API, intended only for use by a generator.\n",
      " |  \n",
      " |  replace_header(self, _name, _value)\n",
      " |      Replace a header.\n",
      " |      \n",
      " |      Replace the first matching header found in the message, retaining\n",
      " |      header order and case.  If no matching header was found, a KeyError is\n",
      " |      raised.\n",
      " |  \n",
      " |  set_boundary(self, boundary)\n",
      " |      Set the boundary parameter in Content-Type to 'boundary'.\n",
      " |      \n",
      " |      This is subtly different than deleting the Content-Type header and\n",
      " |      adding a new one with a new boundary parameter via add_header().  The\n",
      " |      main difference is that using the set_boundary() method preserves the\n",
      " |      order of the Content-Type header in the original message.\n",
      " |      \n",
      " |      HeaderParseError is raised if the message has no Content-Type header.\n",
      " |  \n",
      " |  set_charset(self, charset)\n",
      " |      Set the charset of the payload to a given character set.\n",
      " |      \n",
      " |      charset can be a Charset instance, a string naming a character set, or\n",
      " |      None.  If it is a string it will be converted to a Charset instance.\n",
      " |      If charset is None, the charset parameter will be removed from the\n",
      " |      Content-Type field.  Anything else will generate a TypeError.\n",
      " |      \n",
      " |      The message will be assumed to be of type text/* encoded with\n",
      " |      charset.input_charset.  It will be converted to charset.output_charset\n",
      " |      and encoded properly, if needed, when generating the plain text\n",
      " |      representation of the message.  MIME headers (MIME-Version,\n",
      " |      Content-Type, Content-Transfer-Encoding) will be added as needed.\n",
      " |  \n",
      " |  set_default_type(self, ctype)\n",
      " |      Set the `default' content type.\n",
      " |      \n",
      " |      ctype should be either \"text/plain\" or \"message/rfc822\", although this\n",
      " |      is not enforced.  The default content type is not stored in the\n",
      " |      Content-Type header.\n",
      " |  \n",
      " |  set_param(self, param, value, header='Content-Type', requote=True, charset=None, language='', replace=False)\n",
      " |      Set a parameter in the Content-Type header.\n",
      " |      \n",
      " |      If the parameter already exists in the header, its value will be\n",
      " |      replaced with the new value.\n",
      " |      \n",
      " |      If header is Content-Type and has not yet been defined for this\n",
      " |      message, it will be set to \"text/plain\" and the new parameter and\n",
      " |      value will be appended as per RFC 2045.\n",
      " |      \n",
      " |      An alternate header can be specified in the header argument, and all\n",
      " |      parameters will be quoted as necessary unless requote is False.\n",
      " |      \n",
      " |      If charset is specified, the parameter will be encoded according to RFC\n",
      " |      2231.  Optional language specifies the RFC 2231 language, defaulting\n",
      " |      to the empty string.  Both charset and language should be strings.\n",
      " |  \n",
      " |  set_payload(self, payload, charset=None)\n",
      " |      Set the payload to the given value.\n",
      " |      \n",
      " |      Optional charset sets the message's default character set.  See\n",
      " |      set_charset() for details.\n",
      " |  \n",
      " |  set_raw(self, name, value)\n",
      " |      Store name and value in the model without modification.\n",
      " |      \n",
      " |      This is an \"internal\" API, intended only for use by a parser.\n",
      " |  \n",
      " |  set_type(self, type, header='Content-Type', requote=True)\n",
      " |      Set the main type and subtype for the Content-Type header.\n",
      " |      \n",
      " |      type must be a string in the form \"maintype/subtype\", otherwise a\n",
      " |      ValueError is raised.\n",
      " |      \n",
      " |      This method replaces the Content-Type header, keeping all the\n",
      " |      parameters in place.  If requote is False, this leaves the existing\n",
      " |      header's quoting as is.  Otherwise, the parameters will be quoted (the\n",
      " |      default).\n",
      " |      \n",
      " |      An alternative header can be specified in the header argument.  When\n",
      " |      the Content-Type header is set, we'll always also add a MIME-Version\n",
      " |      header.\n",
      " |  \n",
      " |  set_unixfrom(self, unixfrom)\n",
      " |      # Unix From_ line\n",
      " |  \n",
      " |  values(self)\n",
      " |      Return a list of all the message's header values.\n",
      " |      \n",
      " |      These will be sorted in the order they appeared in the original\n",
      " |      message, or were added to the message, and may contain duplicates.\n",
      " |      Any fields deleted and re-inserted are always appended to the header\n",
      " |      list.\n",
      " |  \n",
      " |  walk(self)\n",
      " |      Walk over the message tree, yielding each subpart.\n",
      " |      \n",
      " |      The walk is performed in depth-first order.  This method is a\n",
      " |      generator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from Message:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(email.message.EmailMessage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the ham/spam emails, but we still need labels. Since it is binary category, we can build it on that and start making this a dataFrame. Before we do that we must deal with an issue, multi-part emails. This can be for a variety of reasons. For instance the emails can have attachements. We need a way to handle this if we are to proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'multipart/alternative',\n",
       " 'multipart/mixed',\n",
       " 'multipart/related',\n",
       " 'multipart/report',\n",
       " 'multipart/signed',\n",
       " 'text/plain'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(email.get_content_type() for email in ham_emails )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_email_structure(email):\n",
    "    if isinstance(email, str): # If it comes out as a string we are bueno. \n",
    "        return email\n",
    "    payload = email.get_payload()#Else we need to look at the payload\n",
    "    if isinstance(payload, list):\n",
    "        return \"multipart({})\".format(\", \".join([\n",
    "            get_email_structure(sub_email) #Recursive\n",
    "            for sub_email in payload #List comphrension \n",
    "        ]))\n",
    "    else:\n",
    "        return email.get_content_type() # At the leaf we return content type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter #collections make me happy.\n",
    "\n",
    "def structures_counter(emails):\n",
    "    structures = Counter()\n",
    "    for email in emails:\n",
    "        structure = get_email_structure(email)\n",
    "        structures[structure] += 1\n",
    "    return structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('text/plain', 2408),\n",
       " ('multipart(text/plain, application/pgp-signature)', 66),\n",
       " ('multipart(text/plain, text/html)', 8),\n",
       " ('multipart(text/plain, text/plain)', 4),\n",
       " ('multipart(text/plain)', 3),\n",
       " ('multipart(text/plain, application/octet-stream)', 2),\n",
       " ('multipart(text/plain, text/enriched)', 1),\n",
       " ('multipart(text/plain, application/ms-tnef, text/plain)', 1),\n",
       " ('multipart(multipart(text/plain, text/plain, text/plain), application/pgp-signature)',\n",
       "  1),\n",
       " ('multipart(text/plain, video/mng)', 1),\n",
       " ('multipart(text/plain, multipart(text/plain))', 1),\n",
       " ('multipart(text/plain, application/x-pkcs7-signature)', 1),\n",
       " ('multipart(text/plain, multipart(text/plain, text/plain), text/rfc822-headers)',\n",
       "  1),\n",
       " ('multipart(text/plain, multipart(text/plain, text/plain), multipart(multipart(text/plain, application/x-pkcs7-signature)))',\n",
       "  1),\n",
       " ('multipart(text/plain, application/x-java-applet)', 1)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structures_counter(ham_emails).most_common() #Collections inherit methods like most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('text/plain', 218),\n",
       " ('text/html', 183),\n",
       " ('multipart(text/plain, text/html)', 45),\n",
       " ('multipart(text/html)', 20),\n",
       " ('multipart(text/plain)', 19),\n",
       " ('multipart(multipart(text/html))', 5),\n",
       " ('multipart(text/plain, image/jpeg)', 3),\n",
       " ('multipart(text/html, application/octet-stream)', 2),\n",
       " ('multipart(text/plain, application/octet-stream)', 1),\n",
       " ('multipart(text/html, text/plain)', 1),\n",
       " ('multipart(multipart(text/html), application/octet-stream, image/jpeg)', 1),\n",
       " ('multipart(multipart(text/plain, text/html), image/gif)', 1),\n",
       " ('multipart/alternative', 1)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structures_counter(spam_emails).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While both have a lit of text/plain content, spam has a much higher proportion of text/html. Ham emails also have applications with a PGP signature. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the headers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return-Path : <12a1mailbot1@web.de>\n",
      "Delivered-To : zzzz@localhost.spamassassin.taint.org\n",
      "Received : from localhost (localhost [127.0.0.1])\tby phobos.labs.spamassassin.taint.org (Postfix) with ESMTP id 136B943C32\tfor <zzzz@localhost>; Thu, 22 Aug 2002 08:17:21 -0400 (EDT)\n",
      "Received : from mail.webnote.net [193.120.211.219]\tby localhost with POP3 (fetchmail-5.9.0)\tfor zzzz@localhost (single-drop); Thu, 22 Aug 2002 13:17:21 +0100 (IST)\n",
      "Received : from dd_it7 ([210.97.77.167])\tby webnote.net (8.9.3/8.9.3) with ESMTP id NAA04623\tfor <zzzz@spamassassin.taint.org>; Thu, 22 Aug 2002 13:09:41 +0100\n",
      "From : 12a1mailbot1@web.de\n",
      "Received : from r-smtp.korea.com - 203.122.2.197 by dd_it7  with Microsoft SMTPSVC(5.5.1775.675.6);\t Sat, 24 Aug 2002 09:42:10 +0900\n",
      "To : dcek1a1@netsgo.com\n",
      "Subject : Life Insurance - Why Pay More?\n",
      "Date : Wed, 21 Aug 2002 20:31:57 -1600\n",
      "MIME-Version : 1.0\n",
      "Message-ID : <0103c1042001882DD_IT7@dd_it7>\n",
      "Content-Type : text/html; charset=\"iso-8859-1\"\n",
      "Content-Transfer-Encoding : quoted-printable\n"
     ]
    }
   ],
   "source": [
    "for header, value in spam_emails[0].items():\n",
    "    print(header,\":\",value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of information can be valuable but the valuable but for this project it is best to keep it simple. Using only the subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Life Insurance - Why Pay More?'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_emails[0][\"Subject\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "#Make the labels and concatenate \n",
    "ham_labels = [0]*len(ham_emails)\n",
    "spam_labels = [1]*len(spam_emails)\n",
    "labels = ham_labels + spam_labels\n",
    "labels = np.array(labels)\n",
    "\n",
    "#Concatenate the data. Must be done it same order \n",
    "emails = ham_emails + spam_emails\n",
    "emails = np.array(emails)\n",
    "X_train, X_test, y_train, y_test = train_test_split(emails, labels,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some interesting quotes...\n",
      "\n",
      "http://www.postfun.com/pfp/worbois.html\n",
      "\n",
      "\n",
      "Thomas Jefferson:\n",
      "\n",
      "\"I have examined all the known superstitions of the word, and I do not\n",
      "find in our particular superstition of Christianity one redeeming feature.\n",
      "They are all alike founded on fables and mythology. Millions of innocent\n",
      "men, women and children, since the introduction of Christianity, have been\n",
      "burnt, tortured, fined and imprisoned. What has been the effect of this\n",
      "coercion? To make one half the world fools and the other half hypocrites;\n",
      "to support roguery and error all over the earth.\"\n",
      "\n",
      "SIX HISTORIC AMERICANS,\n",
      "by John E. Remsburg, letter to William Short\n",
      "Jefferson again:\n",
      "\n",
      "\"Christianity...(has become) the most perverted system that ever shone on\n",
      "man. ...Rogueries, absurdities and untruths were perpetrated upon the\n",
      "teachings of Jesus by a large band of dupes and importers led by Paul, the\n",
      "first great corrupter of the teaching of Jesus.\"\n"
     ]
    }
   ],
   "source": [
    "import bs4 as bs\n",
    "print(X_train[1].get_content().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from html import unescape\n",
    "def html_to_plain_text(html):\n",
    "    text = re.sub('<head.*?>.*?</head>', '', html, flags=re.M | re.S | re.I)#Gets rid of the head section\n",
    "    text = re.sub('<a\\s.*?>', ' HYPERLINK ', text, flags=re.M | re.S | re.I) # Changes <a> tags to the word HYPERLINK\n",
    "    text = re.sub('<.*?>', '', text, flags=re.M | re.S) #Gets rid of any remaining html tags \n",
    "    text = re.sub(r'(\\s*\\n)+', '\\n', text, flags=re.M | re.S)#Replace single newlines with a single newline\n",
    "    return unescape(text) # unescapes html entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OTC\n",
      " Newsletter\n",
      "Discover Tomorrow's Winners \n",
      "For Immediate Release\n",
      "Cal-Bay (Stock Symbol: CBYI)\n",
      "Watch for analyst \"Strong Buy Recommendations\" and several advisory newsletters picking CBYI.  CBYI has filed to be traded on the OTCBB, share prices historically INCREASE when companies get listed on this larger trading exchange. CBYI is trading around 25 cents and should skyrocket to $2.66 - $3.25 a share in the near future.\n",
      "Put CBYI on your watch list, acquire a position TODAY.\n",
      "REASONS TO INVEST IN CBYI\n",
      "A profitable company and is on track to beat ALL earnings estimates!\n",
      "One of the FASTEST growing distributors in environmental & safety equipment instruments.\n",
      "Excellent management team, several EXCLUSIVE contracts.  IMPRESSIVE client list including the U.S. Air Force, Anheuser-Busch, Chevron Refining and Mitsubishi Heavy Industries, GE-Energy & Environmental Research.\n",
      "RAPIDLY GROWING INDUSTRY\n",
      "Industry revenues exceed $900 million, estimates indicate that there could be as much as $25 billi ...\n"
     ]
    }
   ],
   "source": [
    "#Testing \n",
    "html_spam_emails = [email for email in X_train[y_train==1]\n",
    "                    if get_email_structure(email) == \"text/html\"]\n",
    "sample_html_spam = html_spam_emails[7]\n",
    "print(html_to_plain_text(sample_html_spam.get_content())[:1000], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OTC\n",
      " Newsletter\n",
      "Discover Tomorrow's Winners \n",
      "For Immediate Release\n",
      "Cal-Bay (Stock Symbol: CBYI)\n",
      "Wat ...\n"
     ]
    }
   ],
   "source": [
    "#Emails are still in an email byte format\n",
    "def email_to_text(email):\n",
    "    html = None\n",
    "    for part in email.walk():\n",
    "        ctype = part.get_content_type()\n",
    "        if not ctype in (\"text/plain\", \"text/html\"):\n",
    "            continue\n",
    "        try:\n",
    "            content = part.get_content()\n",
    "        except: # in case of encoding issues\n",
    "            content = str(part.get_payload())\n",
    "        if ctype == \"text/plain\":\n",
    "            return content\n",
    "        else:\n",
    "            html = content\n",
    "    if html:\n",
    "        return html_to_plain_text(html)\n",
    "print(email_to_text(sample_html_spam)[:100], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computations => comput\n",
      "Computation => comput\n",
      "Computing => comput\n",
      "Computed => comput\n",
      "Compute => comput\n",
      "Compulsive => compuls\n"
     ]
    }
   ],
   "source": [
    "#Stemming \n",
    "import nltk\n",
    "stemmer = nltk.PorterStemmer()\n",
    "for word in (\"Computations\", \"Computation\", \"Computing\", \"Computed\", \"Compute\", \"Compulsive\"):\n",
    "    print(word, \"=>\", stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also need a way to replace URLs with the word \"URL\". For this, we could use hard core regular expressions but we will just use the urlextract library. You can install it with the following command (don't forget to activate your virtualenv first; if you don't have one, you will likely need administrator rights, or use the --user option):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting urlextract\n",
      "  Downloading urlextract-1.2.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\junglebook\\anaconda3\\lib\\site-packages (from urlextract) (2.8)\n",
      "Collecting appdirs\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\junglebook\\anaconda3\\lib\\site-packages (from urlextract) (3.0.12)\n",
      "Collecting uritools\n",
      "  Downloading uritools-3.0.2-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: uritools, appdirs, urlextract\n",
      "Successfully installed appdirs-1.4.4 uritools-3.0.2 urlextract-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.0.1; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\JungleBook\\Anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install urlextract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['github.com', 'https://youtu.be/7Pq-S557XQU?t=3m32s']\n"
     ]
    }
   ],
   "source": [
    "import urlextract # may require an Internet connection to download root domain names\n",
    "    \n",
    "url_extractor = urlextract.URLExtract()\n",
    "print(url_extractor.find_urls(\"Will it detect github.com and https://youtu.be/7Pq-S557XQU?t=3m32s\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class EmailToWordCounterTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, strip_headers=True, lower_case=True, remove_punctuation=True,\n",
    "                 replace_urls=True, replace_numbers=True, stemming=True):\n",
    "        self.strip_headers = strip_headers\n",
    "        self.lower_case = lower_case\n",
    "        self.remove_punctuation = remove_punctuation\n",
    "        self.replace_urls = replace_urls\n",
    "        self.replace_numbers = replace_numbers\n",
    "        self.stemming = stemming\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = []\n",
    "        for email in X:\n",
    "            text = email_to_text(email) or \"\"\n",
    "            if self.lower_case:\n",
    "                text = text.lower()\n",
    "            if self.replace_urls and url_extractor is not None:\n",
    "                urls = list(set(url_extractor.find_urls(text)))\n",
    "                urls.sort(key=lambda url: len(url), reverse=True)\n",
    "                for url in urls:\n",
    "                    text = text.replace(url, \" URL \")\n",
    "            if self.replace_numbers:\n",
    "                text = re.sub(r'\\d+(?:\\.\\d*)?(?:[eE][+-]?\\d+)?', 'NUMBER', text)\n",
    "            if self.remove_punctuation:\n",
    "                text = re.sub(r'\\W+', ' ', text, flags=re.M)\n",
    "            word_counts = Counter(text.split())\n",
    "            if self.stemming and stemmer is not None:\n",
    "                stemmed_word_counts = Counter()\n",
    "                for word, count in word_counts.items():\n",
    "                    stemmed_word = stemmer.stem(word)\n",
    "                    stemmed_word_counts[stemmed_word] += count\n",
    "                word_counts = stemmed_word_counts\n",
    "            X_transformed.append(word_counts)\n",
    "        return np.array(X_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([Counter({'chuck': 1, 'murcko': 1, 'wrote': 1, 'stuff': 1, 'yawn': 1, 'r': 1}),\n",
       "       Counter({'the': 11, 'of': 9, 'and': 8, 'all': 3, 'christian': 3, 'to': 3, 'by': 3, 'jefferson': 2, 'i': 2, 'have': 2, 'superstit': 2, 'one': 2, 'on': 2, 'been': 2, 'ha': 2, 'half': 2, 'rogueri': 2, 'teach': 2, 'jesu': 2, 'some': 1, 'interest': 1, 'quot': 1, 'url': 1, 'thoma': 1, 'examin': 1, 'known': 1, 'word': 1, 'do': 1, 'not': 1, 'find': 1, 'in': 1, 'our': 1, 'particular': 1, 'redeem': 1, 'featur': 1, 'they': 1, 'are': 1, 'alik': 1, 'found': 1, 'fabl': 1, 'mytholog': 1, 'million': 1, 'innoc': 1, 'men': 1, 'women': 1, 'children': 1, 'sinc': 1, 'introduct': 1, 'burnt': 1, 'tortur': 1, 'fine': 1, 'imprison': 1, 'what': 1, 'effect': 1, 'thi': 1, 'coercion': 1, 'make': 1, 'world': 1, 'fool': 1, 'other': 1, 'hypocrit': 1, 'support': 1, 'error': 1, 'over': 1, 'earth': 1, 'six': 1, 'histor': 1, 'american': 1, 'john': 1, 'e': 1, 'remsburg': 1, 'letter': 1, 'william': 1, 'short': 1, 'again': 1, 'becom': 1, 'most': 1, 'pervert': 1, 'system': 1, 'that': 1, 'ever': 1, 'shone': 1, 'man': 1, 'absurd': 1, 'untruth': 1, 'were': 1, 'perpetr': 1, 'upon': 1, 'a': 1, 'larg': 1, 'band': 1, 'dupe': 1, 'import': 1, 'led': 1, 'paul': 1, 'first': 1, 'great': 1, 'corrupt': 1}),\n",
       "       Counter({'url': 4, 's': 3, 'group': 3, 'to': 3, 'in': 2, 'forteana': 2, 'martin': 2, 'an': 2, 'and': 2, 'we': 2, 'is': 2, 'yahoo': 2, 'unsubscrib': 2, 'y': 1, 'adamson': 1, 'wrote': 1, 'for': 1, 'altern': 1, 'rather': 1, 'more': 1, 'factual': 1, 'base': 1, 'rundown': 1, 'on': 1, 'hamza': 1, 'career': 1, 'includ': 1, 'hi': 1, 'belief': 1, 'that': 1, 'all': 1, 'non': 1, 'muslim': 1, 'yemen': 1, 'should': 1, 'be': 1, 'murder': 1, 'outright': 1, 'know': 1, 'how': 1, 'unbias': 1, 'memri': 1, 'don': 1, 't': 1, 'html': 1, 'rob': 1, 'sponsor': 1, 'number': 1, 'dvd': 1, 'free': 1, 'p': 1, 'join': 1, 'now': 1, 'from': 1, 'thi': 1, 'send': 1, 'email': 1, 'egroup': 1, 'com': 1, 'your': 1, 'use': 1, 'of': 1, 'subject': 1})],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_few = X_train[:3]\n",
    "X_few_wordcounts = EmailToWordCounterTransformer().fit_transform(X_few)\n",
    "X_few_wordcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "class WordCounterToVectorTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, vocabulary_size=1000):\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "    def fit(self, X, y=None):\n",
    "        total_count = Counter()\n",
    "        for word_count in X:\n",
    "            for word, count in word_count.items():\n",
    "                total_count[word] += min(count, 10)\n",
    "        most_common = total_count.most_common()[:self.vocabulary_size]\n",
    "        self.vocabulary_ = {word: index + 1 for index, (word, count) in enumerate(most_common)}\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        rows = []\n",
    "        cols = []\n",
    "        data = []\n",
    "        for row, word_count in enumerate(X):\n",
    "            for word, count in word_count.items():\n",
    "                rows.append(row)\n",
    "                cols.append(self.vocabulary_.get(word, 0))\n",
    "                data.append(count)\n",
    "        return csr_matrix((data, (rows, cols)), shape=(len(X), self.vocabulary_size + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x11 sparse matrix of type '<class 'numpy.intc'>'\n",
       "\twith 20 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_transformer = WordCounterToVectorTransformer(vocabulary_size=10)\n",
    "X_few_vectors = vocab_transformer.fit_transform(X_few_wordcounts)\n",
    "X_few_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [99, 11,  9,  8,  3,  1,  3,  1,  3,  2,  3],\n",
       "       [67,  0,  1,  2,  3,  4,  1,  2,  0,  1,  0]], dtype=int32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_few_vectors.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this matrix mean? Well, the 99 in the second row, first column, means that the second email contains 99 words that are not part of the vocabulary. The 11 next to it means that the first word in the vocabulary is present 11 times in this email. The 9 next to it means that the second word is present 9 times, and so on. You can look at the vocabulary to know which words we are talking about. The first word is \"the\", the second word is \"of\", etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'of': 2,\n",
       " 'and': 3,\n",
       " 'to': 4,\n",
       " 'url': 5,\n",
       " 'all': 6,\n",
       " 'in': 7,\n",
       " 'christian': 8,\n",
       " 'on': 9,\n",
       " 'by': 10}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_transformer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "preprocess_pipeline = Pipeline([\n",
    "    (\"email_to_wordcount\", EmailToWordCounterTransformer()),\n",
    "    (\"wordcount_to_vector\", WordCounterToVectorTransformer()),\n",
    "])\n",
    "\n",
    "X_train_transformed = preprocess_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] .................................... , score=0.981, total=   0.3s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.984, total=   0.5s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.991, total=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9854166666666666"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "log_clf = LogisticRegression(solver=\"lbfgs\", max_iter=1000, random_state=42)\n",
    "score = cross_val_score(log_clf, X_train_transformed, y_train, cv=3, verbose=3)\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 95.88%\n",
      "Recall: 97.89%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "X_test_transformed = preprocess_pipeline.transform(X_test)\n",
    "\n",
    "log_clf = LogisticRegression(solver=\"lbfgs\", max_iter=1000, random_state=42)\n",
    "log_clf.fit(X_train_transformed, y_train)\n",
    "\n",
    "y_pred = log_clf.predict(X_test_transformed)\n",
    "\n",
    "print(\"Precision: {:.2f}%\".format(100 * precision_score(y_test, y_pred)))\n",
    "print(\"Recall: {:.2f}%\".format(100 * recall_score(y_test, y_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
