{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. What is the fundamental idea behind Support Vector Machines?\n",
    "\n",
    "## My Solution \n",
    "\n",
    "Support Vector Machines attempt to minimize the instances within a margin for classification purposes. The larger the margin, the better we are at predicting if something is x or y. Instances on the margin are called support vectors. \n",
    "\n",
    "Likewise, it can be extended to regression. In this we maximize the instances within a margin. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. What is a support vector?\n",
    "\n",
    "## My Solution \n",
    "\n",
    "A support vector is an instance on the margin line, or \"side walk\" of our street.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Why is it important to scale the inputs when using SVMs?\n",
    "\n",
    "## My solution \n",
    "\n",
    "SVMs do not used a closed form equation for minmizing the objective function. More so, the model the margins are sensetive to large magnitueds. Due to this, scaling allows us to maximize our margin and allows us to quickly optimize our cost function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Can an SVM classifier output a confidence score when it classifies an instance? What about a probability?\n",
    "\n",
    "## My solution\n",
    "An SVM classifier does not output a probability as with a logicisitic model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Should you use the primal or the dual form of the SVM problem to train a model on a training set with millions of instances and hundreds of features?\n",
    "\n",
    "## My solution\n",
    "\n",
    "If we do not wish to increase model complexity, it is best to use an optimized classifier. Else we should use the dual form of the SVM problem. The dual problem allows us to easily find our optimized parameters, while leaving the floor open to kernels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Say you’ve trained an SVM classifier with an RBF kernel, but it seems to underfit the training set. Should you increase or decrease γ (gamma)? What about C?\n",
    "\n",
    "## My  Solution \n",
    "\n",
    "If our model is underfitting, we should increase gamma. $C$ follows the same logic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. How should you set the QP parameters (H, f, A, and b) to solve the soft margin linear SVM classifier problem using an off-the-shelf QP solver?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## My solution \n",
    "\n",
    "This was not a question I can immediatly answer, looking at the notes: \n",
    "\n",
    "If we also want to avoid any margin violations (hard margin), then we need the decision function to be greater than 1 for all positive training instances and lower than –1 for negative training instances. If we define t(i) = –1 for negative instances (if y(i) = 0) and t(i) = 1 for positive instances (if y(i) = 1), then we can express this constraint as t(i)(w⊺ x(i) + b) ≥ 1 for all instances.\n",
    "\n",
    "Soft margins can have instances within the margins, because of this our decision function should allow instances in $[-1,1]$. Thus we should change our matrix A.I do not know what exactly to change. \n",
    "\n",
    "\n",
    "## Book Solution \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Train a LinearSVC on a linearly separable dataset. Then train an SVC and a SGDClassifier on the same dataset. See if you can get them to produce roughly the same model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From my understanding, the iris dataset was linearly seperable. \n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris[\"data\"][:, (2, 3)]  # petal length, petal width\n",
    "y = (iris[\"target\"] == 2).astype(np.float64)  # Iris virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size= .1,  random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train) # Should be quick enough to train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('linear_svc',\n",
       "                 LinearSVC(C=1, class_weight=None, dual=True,\n",
       "                           fit_intercept=True, intercept_scaling=1,\n",
       "                           loss='hinge', max_iter=1000, multi_class='ovr',\n",
       "                           penalty='l2', random_state=None, tol=0.0001,\n",
       "                           verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "linear_svc = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"linear_svc\", LinearSVC(C=1, loss=\"hinge\")),\n",
    "    ])\n",
    "linear_svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "y_train_pred = cross_val_predict(linear_svc, X_train, y_train, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9347826086956522"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "precision_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9347826086956522"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far this model is killing it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC with a Guassian Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('svm_clf',\n",
       "                 SVC(C=0.001, break_ties=False, cache_size=200,\n",
       "                     class_weight=None, coef0=0.0,\n",
       "                     decision_function_shape='ovr', degree=3, gamma=5,\n",
       "                     kernel='rbf', max_iter=-1, probability=False,\n",
       "                     random_state=None, shrinking=True, tol=0.001,\n",
       "                     verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "rbf_kernel_svm_clf = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svm_clf\", SVC(kernel=\"rbf\", gamma=5, C=0.001))\n",
    "    ])\n",
    "rbf_kernel_svm_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred = cross_val_predict(rbf_kernel_svm_clf, X_train, y_train, cv=3)\n",
    "precision_score(y_train, y_train_pred, zero_division=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Having some issues with the recall/ precision. Looking at accuracy another way. \n",
    "recall_score(y_train, y_train_pred, zero_division=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rbf_kernel_svm_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7333333333333333"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model needs some improvement. We can use gridsearch to optimize the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = [\n",
    "    {'C': [.25 , .5, 1,2], 'gamma': [.25, .5, 1,2, 3]},\n",
    "  ]\n",
    "\n",
    "svc = SVC(kernel=\"rbf\")\n",
    "grid_search = GridSearchCV(svc, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['C', 'break_ties', 'cache_size', 'class_weight', 'coef0', 'decision_function_shape', 'degree', 'gamma', 'kernel', 'max_iter', 'probability', 'random_state', 'shrinking', 'tol', 'verbose'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                           class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'C': [0.25, 0.5, 1, 2],\n",
       "                          'gamma': [0.25, 0.5, 1, 2, 3]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.25, 'gamma': 2}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('svm_clf',\n",
       "                 SVC(C=0.25, break_ties=False, cache_size=200,\n",
       "                     class_weight=None, coef0=0.0,\n",
       "                     decision_function_shape='ovr', degree=3, gamma=2,\n",
       "                     kernel='rbf', max_iter=-1, probability=False,\n",
       "                     random_state=None, shrinking=True, tol=0.001,\n",
       "                     verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbf_kernel_svm_clf = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svm_clf\", SVC(kernel=\"rbf\", gamma=2, C=0.25))\n",
    "    ])\n",
    "rbf_kernel_svm_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rbf_kernel_svm_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred) #this was what the linearsvc was at "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "m = len(X_train)\n",
    "C =1\n",
    "SGD_class = SGDClassifier(loss=\"hinge\", alpha=1/(m*C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.007407407407407408, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGD_class.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#OverFitts the data? It works well that's for sure! \n",
    "y_pred = SGD_class.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. \n",
    "\n",
    "Train an SVM classifier on the MNIST dataset. Since SVM classifiers are binary classifiers, you will need to use one-versus-the-rest to classify all 10 digits. You may want to tune the hyperparameters using small validation sets to speed up the process. What accuracy can you reach?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'DESCR', 'details', 'categories', 'url'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fetches MNIST Dataset\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note : with a linear SVM classifier. It will automatically use the One-vs-All (also called One-vs-the-Rest, OvR) strategy, so there's nothing special we need to do. Easy!\n",
    "\n",
    "S/O github solutions. I originally thought that I had to split the data into 10 categories for each numeric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_clf = LinearSVC(random_state=42)\n",
    "lin_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9703703703703703"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = lin_clf.predict(X_train)\n",
    "accuracy_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This linear model is certainly too simple for MNIST, but perhaps we just needed to scale the data first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.astype(np.float32))\n",
    "X_test_scaled = scaler.transform(X_test.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9555555555555556"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_clf = LinearSVC(random_state=42)\n",
    "lin_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = lin_clf.predict(X_train_scaled)\n",
    "accuracy_score(y_train, y_pred) #some how made it worse? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we want to use an SVM, we will have to use a kernel. Let's try an SVC with an RBF kernel (the default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9629629629629629"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf = SVC(gamma=\"scale\")\n",
    "svm_clf.fit(X_train_scaled[:10000], y_train[:10000])\n",
    "y_pred = svm_clf.predict(X_train_scaled)\n",
    "accuracy_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] C=9.716094651077585, gamma=0.008487313201851318 .................\n",
      "[CV] .. C=9.716094651077585, gamma=0.008487313201851318, total=   0.0s\n",
      "[CV] C=9.716094651077585, gamma=0.008487313201851318 .................\n",
      "[CV] .. C=9.716094651077585, gamma=0.008487313201851318, total=   0.0s\n",
      "[CV] C=9.716094651077585, gamma=0.008487313201851318 .................\n",
      "[CV] .. C=9.716094651077585, gamma=0.008487313201851318, total=   0.0s\n",
      "[CV] C=5.871892669890743, gamma=0.0037301057716828726 ................\n",
      "[CV] . C=5.871892669890743, gamma=0.0037301057716828726, total=   0.0s\n",
      "[CV] C=5.871892669890743, gamma=0.0037301057716828726 ................\n",
      "[CV] . C=5.871892669890743, gamma=0.0037301057716828726, total=   0.0s\n",
      "[CV] C=5.871892669890743, gamma=0.0037301057716828726 ................\n",
      "[CV] . C=5.871892669890743, gamma=0.0037301057716828726, total=   0.0s\n",
      "[CV] C=6.355427480332562, gamma=0.0031094140544452803 ................\n",
      "[CV] . C=6.355427480332562, gamma=0.0031094140544452803, total=   0.0s\n",
      "[CV] C=6.355427480332562, gamma=0.0031094140544452803 ................\n",
      "[CV] . C=6.355427480332562, gamma=0.0031094140544452803, total=   0.0s\n",
      "[CV] C=6.355427480332562, gamma=0.0031094140544452803 ................\n",
      "[CV] . C=6.355427480332562, gamma=0.0031094140544452803, total=   0.0s\n",
      "[CV] C=4.2571077528699455, gamma=0.055647824444367736 ................\n",
      "[CV] . C=4.2571077528699455, gamma=0.055647824444367736, total=   0.0s\n",
      "[CV] C=4.2571077528699455, gamma=0.055647824444367736 ................\n",
      "[CV] . C=4.2571077528699455, gamma=0.055647824444367736, total=   0.0s\n",
      "[CV] C=4.2571077528699455, gamma=0.055647824444367736 ................\n",
      "[CV] . C=4.2571077528699455, gamma=0.055647824444367736, total=   0.0s\n",
      "[CV] C=6.973736328290276, gamma=0.008420132082025859 .................\n",
      "[CV] .. C=6.973736328290276, gamma=0.008420132082025859, total=   0.0s\n",
      "[CV] C=6.973736328290276, gamma=0.008420132082025859 .................\n",
      "[CV] .. C=6.973736328290276, gamma=0.008420132082025859, total=   0.0s\n",
      "[CV] C=6.973736328290276, gamma=0.008420132082025859 .................\n",
      "[CV] .. C=6.973736328290276, gamma=0.008420132082025859, total=   0.0s\n",
      "[CV] C=4.373547107181192, gamma=0.0018228507345494315 ................\n",
      "[CV] . C=4.373547107181192, gamma=0.0018228507345494315, total=   0.0s\n",
      "[CV] C=4.373547107181192, gamma=0.0018228507345494315 ................\n",
      "[CV] . C=4.373547107181192, gamma=0.0018228507345494315, total=   0.0s\n",
      "[CV] C=4.373547107181192, gamma=0.0018228507345494315 ................\n",
      "[CV] . C=4.373547107181192, gamma=0.0018228507345494315, total=   0.0s\n",
      "[CV] C=2.1917919674897135, gamma=0.02140322030321486 .................\n",
      "[CV] .. C=2.1917919674897135, gamma=0.02140322030321486, total=   0.0s\n",
      "[CV] C=2.1917919674897135, gamma=0.02140322030321486 .................\n",
      "[CV] .. C=2.1917919674897135, gamma=0.02140322030321486, total=   0.0s\n",
      "[CV] C=2.1917919674897135, gamma=0.02140322030321486 .................\n",
      "[CV] .. C=2.1917919674897135, gamma=0.02140322030321486, total=   0.0s\n",
      "[CV] C=3.0647674351893306, gamma=0.07175748007526099 .................\n",
      "[CV] .. C=3.0647674351893306, gamma=0.07175748007526099, total=   0.0s\n",
      "[CV] C=3.0647674351893306, gamma=0.07175748007526099 .................\n",
      "[CV] .. C=3.0647674351893306, gamma=0.07175748007526099, total=   0.0s\n",
      "[CV] C=3.0647674351893306, gamma=0.07175748007526099 .................\n",
      "[CV] .. C=3.0647674351893306, gamma=0.07175748007526099, total=   0.0s\n",
      "[CV] C=8.80349282090189, gamma=0.0022866715598435696 .................\n",
      "[CV] .. C=8.80349282090189, gamma=0.0022866715598435696, total=   0.0s\n",
      "[CV] C=8.80349282090189, gamma=0.0022866715598435696 .................\n",
      "[CV] .. C=8.80349282090189, gamma=0.0022866715598435696, total=   0.0s\n",
      "[CV] C=8.80349282090189, gamma=0.0022866715598435696 .................\n",
      "[CV] .. C=8.80349282090189, gamma=0.0022866715598435696, total=   0.0s\n",
      "[CV] C=1.2824294792958448, gamma=0.07577851101704611 .................\n",
      "[CV] .. C=1.2824294792958448, gamma=0.07577851101704611, total=   0.0s\n",
      "[CV] C=1.2824294792958448, gamma=0.07577851101704611 .................\n",
      "[CV] .. C=1.2824294792958448, gamma=0.07577851101704611, total=   0.0s\n",
      "[CV] C=1.2824294792958448, gamma=0.07577851101704611 .................\n",
      "[CV] .. C=1.2824294792958448, gamma=0.07577851101704611, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                                 class_weight=None, coef0=0.0,\n",
       "                                 decision_function_shape='ovr', degree=3,\n",
       "                                 gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                                 probability=False, random_state=None,\n",
       "                                 shrinking=True, tol=0.001, verbose=False),\n",
       "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001A61CC7ECF8>,\n",
       "                                        'gamma': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001A61CC7EF98>},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import reciprocal, uniform\n",
    "\n",
    "param_distributions = {\"gamma\": reciprocal(0.001, 0.1), \"C\": uniform(1, 10)}\n",
    "rnd_search_cv = RandomizedSearchCV(svm_clf, param_distributions, n_iter=10, verbose=2, cv=3)\n",
    "rnd_search_cv.fit(X_train_scaled[:1000], y_train[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=9.716094651077585, break_ties=False, cache_size=200, class_weight=None,\n",
       "    coef0=0.0, decision_function_shape='ovr', degree=3,\n",
       "    gamma=0.008487313201851318, kernel='rbf', max_iter=-1, probability=False,\n",
       "    random_state=None, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9629629629629629"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9555555555555556"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_estimator_.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = rnd_search_cv.best_estimator_.predict(X_train_scaled)\n",
    "accuracy_score(y_train, y_pred)\n",
    "#I'm surprised this ran quickly on my rig "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rnd_search_cv.best_estimator_.predict(X_test_scaled)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some off reason the linear model fit best. K-cross folds validiton might be useful to verfiy the performance of the model. I gave up after a while and this is what the book did. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. \n",
    "Train an SVM regressor on the California housing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to C:\\Users\\JungleBook\\scikit_learn_data\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X = housing[\"data\"]\n",
    "y = housing[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JungleBook\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_intercept=True,\n",
       "          intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
       "          random_state=42, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "lin_svr = LinearSVR(random_state=42)\n",
    "lin_svr.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9612806653297273"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_pred = lin_svr.predict(X_train_scaled)\n",
    "mse = mean_squared_error(y_train, y_pred)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9804492160890983"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mse) #RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note: Recall that RMSE is almost the equivalent of one standard deviation. Scaling the data means the standard deviation is in units of whatever we are measuring(our label). Thus an RMSE of almost one indicates we have an standard deviation of 1 unit. In this data set we are measuring homes in the cost of 10s of thousands of dollars.\n",
    "\n",
    "In this training set, the targets are tens of thousands of dollars. The RMSE gives a rough idea of the kind of error you should expect (with a higher weight for large errors): so with this model we can expect errors somewhere around $10,000. Not great. Let's see if we can do better with an RBF Kernel. We will use randomized search with cross validation to find the appropriate hyperparameter values for C and gamma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] C=4.745401188473625, gamma=0.07969454818643928 ..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... C=4.745401188473625, gamma=0.07969454818643928, total=   8.9s\n",
      "[CV] C=4.745401188473625, gamma=0.07969454818643928 ..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... C=4.745401188473625, gamma=0.07969454818643928, total=   8.8s\n",
      "[CV] C=4.745401188473625, gamma=0.07969454818643928 ..................\n",
      "[CV] ... C=4.745401188473625, gamma=0.07969454818643928, total=   8.9s\n",
      "[CV] C=8.31993941811405, gamma=0.015751320499779724 ..................\n",
      "[CV] ... C=8.31993941811405, gamma=0.015751320499779724, total=  10.3s\n",
      "[CV] C=8.31993941811405, gamma=0.015751320499779724 ..................\n",
      "[CV] ... C=8.31993941811405, gamma=0.015751320499779724, total=   8.3s\n",
      "[CV] C=8.31993941811405, gamma=0.015751320499779724 ..................\n",
      "[CV] ... C=8.31993941811405, gamma=0.015751320499779724, total=   8.9s\n",
      "[CV] C=2.560186404424365, gamma=0.002051110418843397 .................\n",
      "[CV] .. C=2.560186404424365, gamma=0.002051110418843397, total=   6.7s\n",
      "[CV] C=2.560186404424365, gamma=0.002051110418843397 .................\n",
      "[CV] .. C=2.560186404424365, gamma=0.002051110418843397, total=   7.8s\n",
      "[CV] C=2.560186404424365, gamma=0.002051110418843397 .................\n",
      "[CV] .. C=2.560186404424365, gamma=0.002051110418843397, total=   7.4s\n",
      "[CV] C=1.5808361216819946, gamma=0.05399484409787431 .................\n",
      "[CV] .. C=1.5808361216819946, gamma=0.05399484409787431, total=   6.6s\n",
      "[CV] C=1.5808361216819946, gamma=0.05399484409787431 .................\n",
      "[CV] .. C=1.5808361216819946, gamma=0.05399484409787431, total=   6.9s\n",
      "[CV] C=1.5808361216819946, gamma=0.05399484409787431 .................\n",
      "[CV] .. C=1.5808361216819946, gamma=0.05399484409787431, total=   8.0s\n",
      "[CV] C=7.011150117432088, gamma=0.026070247583707663 .................\n",
      "[CV] .. C=7.011150117432088, gamma=0.026070247583707663, total=  12.2s\n",
      "[CV] C=7.011150117432088, gamma=0.026070247583707663 .................\n",
      "[CV] .. C=7.011150117432088, gamma=0.026070247583707663, total=   7.9s\n",
      "[CV] C=7.011150117432088, gamma=0.026070247583707663 .................\n",
      "[CV] .. C=7.011150117432088, gamma=0.026070247583707663, total=   7.4s\n",
      "[CV] C=1.2058449429580245, gamma=0.0870602087830485 ..................\n",
      "[CV] ... C=1.2058449429580245, gamma=0.0870602087830485, total=   6.3s\n",
      "[CV] C=1.2058449429580245, gamma=0.0870602087830485 ..................\n",
      "[CV] ... C=1.2058449429580245, gamma=0.0870602087830485, total=   8.9s\n",
      "[CV] C=1.2058449429580245, gamma=0.0870602087830485 ..................\n",
      "[CV] ... C=1.2058449429580245, gamma=0.0870602087830485, total=   6.9s\n",
      "[CV] C=9.324426408004218, gamma=0.0026587543983272693 ................\n",
      "[CV] . C=9.324426408004218, gamma=0.0026587543983272693, total=   6.9s\n",
      "[CV] C=9.324426408004218, gamma=0.0026587543983272693 ................\n",
      "[CV] . C=9.324426408004218, gamma=0.0026587543983272693, total=   7.0s\n",
      "[CV] C=9.324426408004218, gamma=0.0026587543983272693 ................\n",
      "[CV] . C=9.324426408004218, gamma=0.0026587543983272693, total=   8.1s\n",
      "[CV] C=2.818249672071006, gamma=0.0023270677083837795 ................\n",
      "[CV] . C=2.818249672071006, gamma=0.0023270677083837795, total=   6.7s\n",
      "[CV] C=2.818249672071006, gamma=0.0023270677083837795 ................\n",
      "[CV] . C=2.818249672071006, gamma=0.0023270677083837795, total=   6.6s\n",
      "[CV] C=2.818249672071006, gamma=0.0023270677083837795 ................\n",
      "[CV] . C=2.818249672071006, gamma=0.0023270677083837795, total=   6.7s\n",
      "[CV] C=4.042422429595377, gamma=0.011207606211860567 .................\n",
      "[CV] .. C=4.042422429595377, gamma=0.011207606211860567, total=   7.0s\n",
      "[CV] C=4.042422429595377, gamma=0.011207606211860567 .................\n",
      "[CV] .. C=4.042422429595377, gamma=0.011207606211860567, total=   6.8s\n",
      "[CV] C=4.042422429595377, gamma=0.011207606211860567 .................\n",
      "[CV] .. C=4.042422429595377, gamma=0.011207606211860567, total=   7.2s\n",
      "[CV] C=5.319450186421157, gamma=0.003823475224675185 .................\n",
      "[CV] .. C=5.319450186421157, gamma=0.003823475224675185, total=   6.8s\n",
      "[CV] C=5.319450186421157, gamma=0.003823475224675185 .................\n",
      "[CV] .. C=5.319450186421157, gamma=0.003823475224675185, total=   6.5s\n",
      "[CV] C=5.319450186421157, gamma=0.003823475224675185 .................\n",
      "[CV] .. C=5.319450186421157, gamma=0.003823475224675185, total=   6.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  3.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3,\n",
       "                                 epsilon=0.1, gamma='scale', kernel='rbf',\n",
       "                                 max_iter=-1, shrinking=True, tol=0.001,\n",
       "                                 verbose=False),\n",
       "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001A61CC808D0>,\n",
       "                                        'gamma': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001A61CC800F0>},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import reciprocal, uniform\n",
    "\n",
    "param_distributions = {\"gamma\": reciprocal(0.001, 0.1), \"C\": uniform(1, 10)}\n",
    "rnd_search_cv = RandomizedSearchCV(SVR(), param_distributions, n_iter=10, verbose=2, cv=3, random_state=42)\n",
    "rnd_search_cv.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=4.745401188473625, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
       "    gamma=0.07969454818643928, kernel='rbf', max_iter=-1, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5727524770785357"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rnd_search_cv.best_estimator_.predict(X_train_scaled)\n",
    "mse = mean_squared_error(y_train, y_pred)\n",
    "np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5929168385528746"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rnd_search_cv.best_estimator_.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our standard deviation is 60% of one unit. About 6000 per standard deviation. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
