{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b291c46",
   "metadata": {},
   "source": [
    "# 1. \n",
    "\n",
    "How would you describe TensorFlow in a short sentence? What are its main features? Can you name other popular Deep Learning libraries?\n",
    "\n",
    "## My Solution \n",
    "\n",
    "TensorFlow is a highly optimized Deep learning library. It has many features that include low-level api, for high level control of neural networks. \n",
    "\n",
    "## Book Solution \n",
    "\n",
    "TensorFlow is an open-source library for numerical computation, particularly well suited and fine-tuned for large-scale Machine Learning. Its core is similar to NumPy, but it also features GPU support, support for distributed computing, computation graph analysis and optimization capabilities (with a portable graph format that allows you to train a TensorFlow model in one environment and run it in another), an optimization API based on reverse-mode autodiff, and several powerful APIs such as tf.keras, tf.data, tf.image, tf.signal, and more. Other popular Deep Learning libraries include PyTorch, MXNet, Microsoft Cognitive Toolkit, Theano, Caffe2, and Chainer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f9cd48",
   "metadata": {},
   "source": [
    "# 2. \n",
    "\n",
    "Is TensorFlow a drop-in replacement for NumPy? What are the main differences between the two?\n",
    "\n",
    "\n",
    "## My Solution \n",
    "\n",
    "TensorFlow is not a drop in replacement for NumpPy. Numpy is used on arrays, while TF is used for tensors. While TF was built in the image of np and even supports its operations. TF is more optimized, is a tensor, and has different defualts(32-bit precision, autograph, etc.)\n",
    "\n",
    "\n",
    "## Book Solution \n",
    "\n",
    "Although TensorFlow offers most of the functionalities provided by NumPy, it is not a drop-in replacement, for a few reasons. First, the names of the functions are not always the same (for example, tf.reduce_sum() versus np.sum()). Second, some functions do not behave in exactly the same way (for example, tf.transpose() creates a transposed copy of a tensor, while NumPy’s T attribute creates a transposed view, without actually copying any data). Lastly, NumPy arrays are mutable, while TensorFlow tensors are not (but you can use a tf.Variable if you need a mutable object)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecf6334",
   "metadata": {},
   "source": [
    "# 3. \n",
    "\n",
    "Do you get the same result with tf.range(10) and tf.constant(np.arange(10))?\n",
    "\n",
    "## My Solution \n",
    "\n",
    "No. This first is an operation of tensorflow, will create an mutable(?) array. The second is a constant contains an array, and is immutable. (I twas wrong)\n",
    "\n",
    "## Book Solution \n",
    "\n",
    "Both tf.range(10) and tf.constant(np.arange(10)) return a one-dimensional tensor containing the integers 0 to 9. However, the former uses 32-bit integers while the latter uses 64-bit integers. Indeed, TensorFlow defaults to 32 bits, while NumPy defaults to 64 bits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77917c8d",
   "metadata": {},
   "source": [
    "# 4. \n",
    "\n",
    "Can you name six other data structures available in TensorFlow, beyond regular tensors?\n",
    "\n",
    "## My Solution \n",
    "\n",
    "Sparse Tensors, String Tensors, float tensors, integer tensors, sets, and queues. \n",
    "\n",
    "\n",
    "## Book Solution \n",
    "\n",
    "Beyond regular tensors, TensorFlow offers several other data structures, including sparse tensors, tensor arrays, ragged tensors, queues, string tensors, and sets. The last two are actually represented as regular tensors, but TensorFlow provides special functions to manipulate them (in tf.strings and tf.sets).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4827dbf6",
   "metadata": {},
   "source": [
    "# 5. \n",
    "\n",
    "A custom loss function can be defined by writing a function or by subclassing the keras.losses.Loss class. When would you use each option?\n",
    "\n",
    "## My Solution \n",
    "\n",
    "The first does cannot be saved and is not easily tracked. The second can be saved and supports streaming metrics. Use either when keras does not have the loss you want to use. (I was mussing a lot, so lets say I was wrong)\n",
    "\n",
    "\n",
    "\n",
    "## Book Solution \n",
    "\n",
    "When you want to define a custom loss function, in general you can just implement it as a regular Python function. However, if your custom loss function must support some hyperparameters (or any other state), then you should subclass the keras.losses.Loss class and implement the __init__() and call() methods. If you want the loss function’s hyperparameters to be saved along with the model, then you must also implement the get_config() method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29521925",
   "metadata": {},
   "source": [
    "# 6. \n",
    "\n",
    "Similarly, a custom metric can be defined in a function or a subclass of keras.metrics.Metric. When would you use each option?\n",
    "\n",
    "## My Solution \n",
    "\n",
    "Similar to the last question. Use a function simply computing a custom metric, and one that does not require streaming. The other is great for saving and streaming.  (Let's say I was wrong.)\n",
    "\n",
    "\n",
    "## Book Solution \n",
    "\n",
    "Much like custom loss functions, most metrics can be defined as regular Python functions. But if you want your custom metric to support some hyperparameters (or any other state), then you should subclass the keras.metrics.Metric class. Moreover, if computing the metric over a whole epoch is not equivalent to computing the mean metric over all batches in that epoch (e.g., as for the precision and recall metrics), then you should subclass the keras.metrics.Metric class and implement the __init__(), update_state(), and result() methods to keep track of a running metric during each epoch. You should also implement the reset_states() method unless all it needs to do is reset all variables to 0.0. If you want the state to be saved along with the model, then you should implement the get_config() method as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d032720d",
   "metadata": {},
   "source": [
    "# 7. \n",
    "\n",
    "When should you create a custom layer versus a custom model?\n",
    "\n",
    "## My Solution \n",
    "\n",
    "A custom layer is great for repititive layers. It can mimic the repeated layers, while cleaning the up the code. It is great for making layers not found with keras, that you wish to integrate into a usual model. A custom model is great if you wish to track metrics beyond basic, while utilizing compile,fit, predict, and various other methods. That it is not being passed into a model, it is the model. \n",
    "\n",
    "\n",
    "## Book Solution \n",
    "\n",
    "You should distinguish the internal components of your model (i.e., layers or reusable blocks of layers) from the model itself (i.e., the object you will train). The former should subclass the keras.layers.Layer class, while the latter should subclass the keras.models.Model class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb27ab58",
   "metadata": {},
   "source": [
    "# 8. \n",
    "\n",
    "What are some use cases that require writing your own custom training loop?\n",
    "\n",
    "## My Solution \n",
    "\n",
    "If we wish to ignore backpropagation for a subset of neurons/layers. Use a method that is not backpropogatoin.(I missed a ton)\n",
    "\n",
    "\n",
    "## Book Solution \n",
    "\n",
    "Writing your own custom training loop is fairly advanced, so you should only do it if you really need to. Keras provides several tools to customize training without having to write a custom training loop: callbacks, custom regularizers, custom constraints, custom losses, and so on. You should use these instead of writing a custom training loop whenever possible: writing a custom training loop is more error-prone, and it will be harder to reuse the custom code you write. However, in some cases writing a custom training loop is necessary⁠—for example, if you want to use different optimizers for different parts of your neural network, like in the Wide & Deep paper. A custom training loop can also be useful when debugging, or when trying to understand exactly how training works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187464b2",
   "metadata": {},
   "source": [
    "# 9. \n",
    "\n",
    "Can custom Keras components contain arbitrary Python code, or must they be convertible to TF Functions?\n",
    "\n",
    "## My Solution \n",
    "\n",
    "Things must be convertible to TF functions. \n",
    "\n",
    "\n",
    "## Book Solution \n",
    "\n",
    "Custom Keras components should be convertible to TF Functions, which means they should stick to TF operations as much as possible and respect all the rules listed in “TF Function Rules”. If you absolutely need to include arbitrary Python code in a custom component, you can either wrap it in a tf.py_function() operation (but this will reduce performance and limit your model’s portability) or set dynamic=True when creating the custom layer or model (or set run_eagerly=True when calling the model’s compile() method)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26502e97",
   "metadata": {},
   "source": [
    "# 10. \n",
    "\n",
    "What are the main rules to respect if you want a function to be convertible to a TF Function?\n",
    "\n",
    "## My Solution \n",
    "\n",
    "Use Python built-ins, and Numpy. \n",
    "\n",
    "## Book Solution \n",
    "\n",
    "Please refer to “TF Function Rules” for the list of rules to respect when creating a TF Function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f222b278",
   "metadata": {},
   "source": [
    "# 11. \n",
    "\n",
    "When would you need to create a dynamic Keras model? How do you do that? Why not make all your models dynamic?\n",
    "\n",
    "## My Solution \n",
    "\n",
    "This requires resizing and takes a while to complete. Heck, resizing for 1-d arrays takes O(n) times. \n",
    "\n",
    "\n",
    "## Book Solution "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
