{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a82c0807",
   "metadata": {},
   "source": [
    "1. \n",
    "\n",
    "The TensorFlow Playground is a handy neural network simulator built by the TensorFlow team. In this exercise, you will train several binary classifiers in just a few clicks, and tweak the model’s architecture and its hyperparameters to gain some intuition on how neural networks work and what their hyperparameters do. Take some time to explore the following:\n",
    "\n",
    "a. \n",
    "\n",
    "    The patterns learned by a neural net. Try training the default neural network by clicking the Run button (top left). Notice how it quickly finds a good solution for the classification task. The neurons in the first hidden layer have learned simple patterns, while the neurons in the second hidden layer have learned to combine the simple patterns of the first hidden layer into more complex patterns. In general, the more layers there are, the more complex the patterns can be.\n",
    "\n",
    "b. \n",
    "\n",
    "    Activation functions. Try replacing the tanh activation function with a ReLU activation function, and train the network again. Notice that it finds a solution even faster, but this time the boundaries are linear. This is due to the shape of the ReLU function.\n",
    "\n",
    "c. \n",
    "\n",
    "    The risk of local minima. Modify the network architecture to have just one hidden layer with three neurons. Train it multiple times (to reset the network weights, click the Reset button next to the Play button). Notice that the training time varies a lot, and sometimes it even gets stuck in a local minimum.\n",
    "\n",
    "d.\n",
    "\n",
    "    What happens when neural nets are too small. Remove one neuron to keep just two. Notice that the neural network is now incapable of finding a good solution, even if you try multiple times. The model has too few parameters and systematically underfits the training set.\n",
    "\n",
    "e. \n",
    "\n",
    "    What happens when neural nets are large enough. Set the number of neurons to eight, and train the network several times. Notice that it is now consistently fast and never gets stuck. This highlights an important finding in neural network theory: large neural networks almost never get stuck in local minima, and even when they do these local optima are almost as good as the global optimum. However, they can still get stuck on long plateaus for a long time.\n",
    "\n",
    "f. \n",
    "\n",
    "    The risk of vanishing gradients in deep networks. Select the spiral dataset (the bottom-right dataset under “DATA”), and change the network architecture to have four hidden layers with eight neurons each. Notice that training takes much longer and often gets stuck on plateaus for long periods of time. Also notice that the neurons in the highest layers (on the right) tend to evolve faster than the neurons in the lowest layers (on the left). This problem, called the “vanishing gradients” problem, can be alleviated with better weight initialization and other techniques, better optimizers (such as AdaGrad or Adam), or Batch Normalization (discussed in Chapter 11).\n",
    "\n",
    "g. \n",
    "\n",
    "    Go further. Take an hour or so to play around with other parameters and get a feel for what they do, to build an intuitive understanding about neural networks.\n",
    "    \n",
    "    \n",
    "For this assignment we follow the [link](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.49314&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false)\n",
    "\n",
    "The playground is pretty fun, I see why ReLU is used over other activation functions. It provides immense speed at for large models. Linear and sigmoid work best lesser hiden layers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07961832",
   "metadata": {},
   "source": [
    "# 2. \n",
    "\n",
    "Draw an ANN using the original artificial neurons (like the ones in Figure 10-3) that computes A ⊕ B (where ⊕ represents the XOR operation). Hint: A ⊕ B = (A ∧ ¬ B) ∨ (¬ A ∧ B)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c389fa29",
   "metadata": {},
   "source": [
    "# 3. \n",
    "\n",
    "Why is it generally preferable to use a Logistic Regression classifier rather than a classical Perceptron (i.e., a single layer of threshold logic units trained using the Perceptron training algorithm)? How can you tweak a Perceptron to make it equivalent to a Logistic Regression classifier?\n",
    "\n",
    "## My Solution \n",
    "\n",
    "While logistic regression is linear, it uses a step function which alter's its curve. While a sinhle layer perceptron is completly linear and rather than compute a 1 or 0, would make some value in 0 and 1. \n",
    "\n",
    "We can tweak a perceptron by increasing adding hidden layers and changing the activation function. A sigmoid function might suffice. \n",
    "\n",
    "## Book Solution \n",
    "\n",
    "A classical Perceptron will converge only if the dataset is linearly separable, and it won’t be able to estimate class probabilities. In contrast, a Logistic Regression classifier will generally converge to a reasonably good solution even if the dataset is not linearly separable, and it will output class probabilities. If you change the Perceptron’s activation function to the logistic activation function (or the softmax activation function if there are multiple neurons), and if you train it using Gradient Descent (or some other optimization algorithm minimizing the cost function, typically cross entropy), then it becomes equivalent to a Logistic Regression classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a67cf3",
   "metadata": {},
   "source": [
    "# 4. \n",
    "\n",
    "Why was the logistic activation function a key ingredient in training the first MLPs?\n",
    "\n",
    "## My Solution \n",
    "\n",
    "It provides a probability that the instance belongs in a postive class. Like ensemble learning it can better weight its own decisions if it has this. \n",
    "\n",
    "## Book Solution \n",
    "\n",
    "The logistic activation function was a key ingredient in training the first MLPs because its derivative is always nonzero, so Gradient Descent can always roll down the slope. When the activation function is a step function, Gradient Descent cannot move, as there is no slope at all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdb4c7b",
   "metadata": {},
   "source": [
    "# 5 \n",
    "\n",
    "Name three popular activation functions. Can you draw them? \n",
    "\n",
    "## My Solution \n",
    "\n",
    "Three popular activation functions are ReLU, tanh, and the sigmoid(logistic) function. \n",
    "\n",
    "Rectified linear unit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "073bbfd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x18cf38714c0>]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "x = list(range(-10,10))\n",
    "def ReLU(x):\n",
    "    return max(0,x);\n",
    "y = [ReLU(i) for i in x ]\n",
    "plt.plot(x, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a5e1bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x18cf3961550>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/ (1 + np.exp(-x))\n",
    "y = [sigmoid(i) for i in x] \n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a8794ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x18cf39c93d0>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tanh(x):\n",
    "    return (np.exp(x)- np.exp(-x)) / (np.exp(x) + np.exp(-x))\n",
    "y = [tanh(i) for i in x]\n",
    "plt.plot(x,y) #I thought this would be hyperbolic, like a second degree polynomial. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c1db94",
   "metadata": {},
   "source": [
    "# 6. \n",
    "\n",
    "Suppose you have an MLP composed of one input layer with 10 passthrough neurons, followed by one hidden layer with 50 artificial neurons, and finally one output layer with 3 artificial neurons. All artificial neurons use the ReLU activation function.\n",
    "\n",
    "\n",
    "- What is the shape of the input matrix X?\n",
    "\n",
    "- What are the shapes of the hidden layer’s weight vector $W_h$ and its bias vector $b_h$?\n",
    "\n",
    "- What are the shapes of the output layer’s weight vector $W_o$ and its bias vector $b_o$?\n",
    "\n",
    "- What is the shape of the network’s output matrix Y?\n",
    "\n",
    "- Write the equation that computes the network’s output matrix Y as a function of X, $W_h$, $b_h$, $W_o$, and $b_o$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa48e5f",
   "metadata": {},
   "source": [
    "## My solution \n",
    "\n",
    "The shape of the input matrix sohuld be a 10 by 10? \n",
    "\n",
    "The A weight vector have one row per input neuron and one column for each artifical neuron in the hidden layer. Therefor it should be (10,50). There should be one bias neuron per artifical neuron in the layer.Thus the bias vector should be of size (50).\n",
    "\n",
    "The shaped of the output weight vector should be (50,3). The bias vector should be of shape, (3).\n",
    "\n",
    "The shape of the networks output matrix y should be (3,3)\n",
    "\n",
    "$$h_{(W,b)}(X)=ϕ(XW+b) $$\n",
    "\n",
    "## Book Solution \n",
    "\n",
    "Considering the MLP described in the question, composed of one input layer with 10 passthrough neurons, followed by one hidden layer with 50 artificial neurons, and finally one output layer with 3 artificial neurons, where all artificial neurons use the ReLU activation function:\n",
    "\n",
    "The shape of the input matrix X is m × 10, where m represents the training batch size.\n",
    "\n",
    "The shape of the hidden layer’s weight vector Wh is 10 × 50, and the length of its bias vector bh is 50.\n",
    "\n",
    "The shape of the output layer’s weight vector Wo is 50 × 3, and the length of its bias vector bo is 3.\n",
    "\n",
    "The shape of the network’s output matrix Y is m × 3.\n",
    "\n",
    "$Y* = ReLU(ReLU(X W_h + b_h) W_o + b_o)$. Recall that the ReLU function just sets every negative number in the matrix to zero. Also note that when you are adding a bias vector to a matrix, it is added to every single row in the matrix, which is called broadcasting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01f0f96",
   "metadata": {},
   "source": [
    "# 7. \n",
    "\n",
    "How many neurons do you need in the output layer if you want to classify email into spam or ham? What activation function should you use in the output layer? If instead you want to tackle MNIST, how many neurons do you need in the output layer, and which activation function should you use? What about for getting your network to predict housing prices, as in Chapter 2?\n",
    "\n",
    "# My solution \n",
    "\n",
    "For Ham or Spam we should create a model with a single neurons in the output layer. The activation function can be Sigmoid activiation function.\n",
    "\n",
    "In the Fashion MNIST dataset we need a n output layer with 10 neurons, one for each class.  The activation function is the softmax function ensures the neurons add up to one. \n",
    "\n",
    "To predict housing prices we have a regression problem. Thus we need a sigle output neuron. More so the activation function can be RELU. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8746e442",
   "metadata": {},
   "source": [
    "## Book Solution \n",
    "\n",
    "If you want your neural network to predict housing prices like in Chapter 2, then you need one output neuron, using no activation function at all in the output layer.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719456ac",
   "metadata": {},
   "source": [
    "# 8. \n",
    "\n",
    "What is backpropagation and how does it work? What is the difference between backpropagation and reverse-mode autodiff?\n",
    "\n",
    "\n",
    "## My solution \n",
    "\n",
    "Backpropagation is similar to a gradient discent algorithm. It trains the model and at the end measures error. It measures the error at each layer, finding the gradient and performing gradient discent on the weights. This should reduce error for each epoch. \n",
    "\n",
    "Reverse mode autodiff is the process utilized in backpropagation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee03cfd",
   "metadata": {},
   "source": [
    "# 9. \n",
    "\n",
    "Can you list all the hyperparameters you can tweak in a basic MLP? If the MLP overfits the training data, how could you tweak these hyperparameters to try to solve the problem?\n",
    "\n",
    "## My solution\n",
    "\n",
    "The hyperparameters are: Neurons, layers, activation functions, learning rate, regularization, and batch size.\n",
    "\n",
    "If an MLP was overfiting we can reduce the number of laters, remove/reduce regularization and reduve the batch size from a large number to 32. \n",
    "\n",
    "## Book Solution \n",
    "\n",
    "Here is a list of all the hyperparameters you can tweak in a basic MLP: the number of hidden layers, the number of neurons in each hidden layer, and the activation function used in each hidden layer and in the output layer.4 In general, the ReLU activation function (or one of its variants; see Chapter 11) is a good default for the hidden layers. For the output layer, in general you will want the logistic activation function for binary classification, the softmax activation function for multiclass classification, or no activation function for regression.\n",
    "\n",
    "If the MLP overfits the training data, you can try reducing the number of hidden layers and reducing the number of neurons per hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f756c4f",
   "metadata": {},
   "source": [
    "# 10. \n",
    "\n",
    "Train a deep MLP on the MNIST dataset (you can load it using keras.datasets.mnist.load_data(). See if you can get over 98% precision. Try searching for the optimal learning rate by using the approach presented in this chapter (i.e., by growing the learning rate exponentially, plotting the loss, and finding the point where the loss shoots up). Try adding all the bells and whistles—save checkpoints, use early stopping, and plot learning curves using TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b580728d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "833d9809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A good classifcation set would be the MNIST Fashion dataset covered ealier in the chatper \n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf019565",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The algorithm will be trained with gradient discent\n",
    "#Thus regularization will be needed \n",
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ca35089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Fashion MNIST we need the list of class names to know what we are dealing with:\n",
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e7c9f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a lib for the logs \n",
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"exercise10_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir() # e.g., './my_logs/run_2019_06_07-15_15_22'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb090db",
   "metadata": {},
   "source": [
    "### Exp method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de389849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I had not idea how to use the exp method so I took it from the solutions\n",
    "K = keras.backend\n",
    "\n",
    "class ExponentialLearningRate(keras.callbacks.Callback):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        self.rates = []\n",
    "        self.losses = []\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.rates.append(K.get_value(self.model.optimizer.lr))\n",
    "        self.losses.append(logs[\"loss\"])\n",
    "        K.set_value(self.model.optimizer.lr, self.model.optimizer.lr * self.factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ccea2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JungleBook\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])\n",
    "expon_lr = ExponentialLearningRate(factor=1.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af213fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 7s 4ms/step - loss: 1.5519 - accuracy: 0.5125 - val_loss: 2.3313 - val_accuracy: 0.1024\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[expon_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43113a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(expon_lr.rates, expon_lr.losses)\n",
    "plt.gca().set_xscale('log')\n",
    "plt.hlines(min(expon_lr.losses), min(expon_lr.rates), max(expon_lr.rates))\n",
    "plt.axis([min(expon_lr.rates), max(expon_lr.rates), 0, expon_lr.losses[0]])\n",
    "plt.grid()\n",
    "plt.xlabel(\"Learning rate\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee4d0af",
   "metadata": {},
   "source": [
    "The point where loss shots up violently is about .5. Lets try using half that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cc9fc40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nhistory = keras_reg.fit(X_train, y_train, epochs=100,\\n              validation_data=(X_valid, y_valid), \\n              callbacks=[keras.callbacks.EarlyStopping(patience=10),tensorboard_cb ])\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The description of this probem, makes me assume we are using a function to do this \n",
    "def build_model(n_hidden=2, n_neurons=30, learning_rate=25e-2, input_shape=[28,28]):\n",
    "    model = keras.models.Sequential() # Structure of model\n",
    "    model.add(keras.layers.Flatten(input_shape=input_shape)) #Input layer\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\")) ##hidden layers\n",
    "    model.add(keras.layers.Dense(10, activation=\"softmax\"))#output later\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate) # activation function \n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics = [\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "#Wrap the function as a keras model \n",
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n",
    "\n",
    "#Declare where the callback logs will go\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_mnist_model.h5\", save_best_only=True)\n",
    "\n",
    "#Code below is for a single run. \n",
    "\"\"\"\n",
    "history = keras_reg.fit(X_train, y_train, epochs=100,\n",
    "              validation_data=(X_valid, y_valid), \n",
    "              callbacks=[keras.callbacks.EarlyStopping(patience=10),tensorboard_cb ])\n",
    "\"\"\"\n",
    "#We need a way of trying a lot of different things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6a0cd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JungleBook\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 8 is smaller than n_iter=10. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\JungleBook\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.8673 - accuracy: 0.7696 - val_loss: 0.8408 - val_accuracy: 0.7604\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.6929 - accuracy: 0.8131 - val_loss: 0.9396 - val_accuracy: 0.7890\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.6669 - accuracy: 0.8186 - val_loss: 0.8047 - val_accuracy: 0.8066\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.6194 - accuracy: 0.8292 - val_loss: 0.5157 - val_accuracy: 0.8472\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.6052 - accuracy: 0.8274 - val_loss: 0.7076 - val_accuracy: 0.8192\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5898 - accuracy: 0.8325 - val_loss: 0.6704 - val_accuracy: 0.7966\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.6047 - accuracy: 0.8316 - val_loss: 0.5287 - val_accuracy: 0.8484\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.5836 - accuracy: 0.8346 - val_loss: 0.6341 - val_accuracy: 0.8252\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.5741 - accuracy: 0.8377 - val_loss: 0.6834 - val_accuracy: 0.8078\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5723 - accuracy: 0.8373 - val_loss: 0.7120 - val_accuracy: 0.7942\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5811 - accuracy: 0.8365 - val_loss: 0.5093 - val_accuracy: 0.8510\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5688 - accuracy: 0.8396 - val_loss: 0.5703 - val_accuracy: 0.8486\n",
      "Epoch 13/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5658 - accuracy: 0.8399 - val_loss: 0.5764 - val_accuracy: 0.8208\n",
      "Epoch 14/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5651 - accuracy: 0.8392 - val_loss: 0.8088 - val_accuracy: 0.8102\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5682 - accuracy: 0.8418 - val_loss: 0.6970 - val_accuracy: 0.8192\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5655 - accuracy: 0.8400 - val_loss: 0.5714 - val_accuracy: 0.8492\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5545 - accuracy: 0.8428 - val_loss: 1.2525 - val_accuracy: 0.8062\n",
      "Epoch 18/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5591 - accuracy: 0.8419 - val_loss: 0.5382 - val_accuracy: 0.8534\n",
      "Epoch 19/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5516 - accuracy: 0.8414 - val_loss: 0.6733 - val_accuracy: 0.8130\n",
      "Epoch 20/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.5518 - accuracy: 0.8449 - val_loss: 0.5477 - val_accuracy: 0.8326\n",
      "Epoch 21/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5576 - accuracy: 0.8428 - val_loss: 0.5461 - val_accuracy: 0.8522\n",
      "573/573 [==============================] - 1s 2ms/step - loss: 0.5606 - accuracy: 0.8407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JungleBook\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.9371 - accuracy: 0.7626 - val_loss: 0.7040 - val_accuracy: 0.8026\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.7118 - accuracy: 0.8079 - val_loss: 0.4999 - val_accuracy: 0.8394\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.6720 - accuracy: 0.8142 - val_loss: 0.6209 - val_accuracy: 0.8346\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.6588 - accuracy: 0.8205 - val_loss: 0.5662 - val_accuracy: 0.8274\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.6268 - accuracy: 0.8258 - val_loss: 0.6027 - val_accuracy: 0.8336\n",
      "Epoch 6/100\n",
      " 562/1146 [=============>................] - ETA: 0s - loss: 0.6106 - accuracy: 0.8266"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-0ca61e26f93a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mrnd_search_cv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_reg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_distribs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m rnd_search_cv.fit(X_train, y_train, epochs=100,\n\u001b[0m\u001b[0;32m     11\u001b[0m                   \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                   callbacks=[keras.callbacks.EarlyStopping(patience=10), tensorboard_cb, checkpoint_cb])\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1618\u001b[0m         \u001b[1;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1619\u001b[1;33m         evaluate_candidates(ParameterSampler(\n\u001b[0m\u001b[0;32m   1620\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1621\u001b[0m             random_state=self.random_state))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1044\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1045\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    591\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": [20 , 300],\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10), tensorboard_cb, checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f476e96",
   "metadata": {},
   "source": [
    "The book solution for this can be found [here](https://github.com/ageron/handson-ml2/blob/master/10_neural_nets_with_keras.ipynb). The one thing I didn't know how to do was use the exponential learning rate. They do it in the solution and it is a great way to quickly find the learning rate! They didn't do any hyperparameter tunning and I assumed it would be needed. \n",
    "\n",
    "Using the exponential learning rate is a greate way to reduce time spent in hyperparameter tunning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe5462ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 5172), started 0:48:49 ago. (Use '!kill 5172' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-164372b23a2d9085\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-164372b23a2d9085\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./exercise10_logs --port=6006"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
